{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852297ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "session_cookie = 'ditbt0fhh52pl7tnwhzchsriz8ahzd27'\n",
    "RFNSA_No = '3922002'\n",
    "\n",
    "def download_file_from_google_colab(output_file_path):\n",
    "    from google.colab import files\n",
    "    files.download(output_file_path)\n",
    "    print(f\"File downloaded: {output_file_path}\")\n",
    "\n",
    "def start_Session():\n",
    "    \"\"\"\n",
    "    Start the session reusing the underlying TCP connection for multiple requests as\n",
    "    well as with gzip compression and randomly selected useragent \n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.headers.update({'Accept-Encoding': 'gzip'})\n",
    "    return session\n",
    "\n",
    "session = start_Session()\n",
    "# Send a GET request to the URL\n",
    "response = session.get('https://www.rfnsa.com.au/'+ RFNSA_No +'/documents', headers={'User-Agent':'Mozilla/5.0 (Linux; Android 12; SM-S906N Build/QP1A.190711.020; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/80.0.3987.119 Mobile Safari/537.36',\n",
    "                        'Cookie': 'sessionid='+session_cookie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    pattern = re.compile('.*var rfnsaSid = \"(.*)\"')\n",
    "    script = soup.find_all('script', string=pattern)\n",
    "    sid = pattern.match(script[0].text.replace('\\n','')).group(1)\n",
    "    \n",
    "\n",
    "    projects_docs = soup.findAll(\"tr\", {'class':['test-project-doc']})\n",
    "    site_docs = soup.findAll(\"tr\", {'class':['test-site-doc']})\n",
    "    \n",
    "    for p in range(0, len(projects_docs)):\n",
    "        project_date = projects_docs[p].find_all(\"td\")[0].get_text(strip=True)\n",
    "        carrier = projects_docs[p].find_all(\"td\")[1].get_text(strip=True)\n",
    "        project_name = projects_docs[p].find_all(\"td\")[2].get_text(strip=True).replace(carrier,'').replace('Co.','').strip()\n",
    "        System = projects_docs[p].find_all(\"td\")[3].get_text(strip=True)\n",
    "        id_documents = projects_docs[p].find_all(\"td\")[4].find('a')['data-target'].replace('#','')\n",
    "        #documents = soup.find(\"div\", {\"id\": id_documents}).find_all(\"tr\", class_=\"test-project-inner-doc clickable-row\")\n",
    "        documents = soup.find(\"div\", {\"id\": id_documents}).find_all(\"tr\", {'class':['test-project-inner-doc clickable-row']})\n",
    "\n",
    "        for d in range(0,len(documents)):\n",
    "            document_name = documents[d].find_all('td')[0].get_text(separator = '\\n', strip = True).split('\\n')[1]\n",
    "            upload_date = datetime.strptime(documents[d].find_all('td')[2].text, '%d %b %Y %H:%M:%S').strftime('%Y-%m-%d')\n",
    "            document_url = 'https://www.rfnsa.com.au'+ documents[d].find_all('a')[1]['data-url'].replace('embed','download').replace('-pdf','') + '?target=blank&sid=' + sid\n",
    "            #print(document_url)\n",
    "            file_name =  f\"{RFNSA_No}_{carrier}_{project_name}_{upload_date.replace(' ', '_')}_{document_name}\"\n",
    "\n",
    "            document_response = session.get(document_url, headers={'User-Agent':'Mozilla/5.0 (Linux; Android 12; SM-S906N Build/QP1A.190711.020; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/80.0.3987.119 Mobile Safari/537.36',\n",
    "                            'Cookie': session_cookie})  \n",
    "            if document_response.status_code == 200:\n",
    "                    # Save the document with the new name\n",
    "                    with open(file_name, \"wb\") as file:\n",
    "                        file.write(document_response.content)\n",
    "                        if 'google.colab' in str(get_ipython()):\n",
    "                            download_file_from_google_colab(file_name)\n",
    "                    print(f\"Downloaded: {file_name}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {document_url}\")\n",
    "                \n",
    "    for p in range(0, len(site_docs)):\n",
    "        project_date = site_docs[p].find_all(\"td\")[0].get_text(strip=True)\n",
    "        \n",
    "        carrier = site_docs[p].find_all(\"td\")[1].get_text(strip=True)\n",
    "        if carrier:\n",
    "            carrier = '_' + carrier\n",
    "            \n",
    "        project_name = site_docs[p].find_all(\"td\")[2].get_text(strip=True).replace(carrier,'').replace('Co.','').strip()\n",
    "        if project_name:\n",
    "            project_name = '_' + project_name\n",
    "            \n",
    "        System = site_docs[p].find_all(\"td\")[3].get_text(strip=True)\n",
    "        id_documents = site_docs[p].find_all(\"td\")[4].find('a')['data-target'].replace('#','')\n",
    "        documents = soup.find(\"div\", {\"id\": id_documents}).select('tr.test-site-inner-doc.clickable-row')\n",
    "\n",
    "        for d in range(0,len(documents)):\n",
    "            document_name_custom = documents[d].find_all('td')[0].get_text(separator = '\\n', strip = True).split('\\n')[0]\n",
    "            document_name = documents[d].find_all('td')[0].get_text(separator = '\\n', strip = True).split('\\n')[1]\n",
    "            \n",
    "            for s in re.split('[_| .]+',document_name):\n",
    "                document_name_custom2 = re.sub(s, '', document_name_custom, flags=re.I)\n",
    "                document_name_custom = document_name_custom2.strip()\n",
    "            document_name_custom = \" \".join(document_name_custom2.split())\n",
    "            \n",
    "            upload_date = datetime.strptime(documents[d].find_all('td')[2].text, '%d %b %Y %H:%M:%S').strftime('%Y-%m-%d')\n",
    "            document_url = 'https://www.rfnsa.com.au'+ documents[d].select('a.download-document')[0]['data-url']\n",
    "            #print(document_url)\n",
    "            file_name =  f\"{RFNSA_No}{carrier}{project_name}_{upload_date.replace(' ', '_')}_{document_name_custom}_{document_name}\"\n",
    "\n",
    "            document_response = session.get(document_url, headers={'User-Agent':'Mozilla/5.0 (Linux; Android 12; SM-S906N Build/QP1A.190711.020; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/80.0.3987.119 Mobile Safari/537.36',\n",
    "                            'Cookie': session_cookie})  \n",
    "            if document_response.status_code == 200:\n",
    "                    # Save the document with the new name\n",
    "                    with open(file_name, \"wb\") as file:\n",
    "                        file.write(document_response.content)\n",
    "                        if 'google.colab' in str(get_ipython()):\n",
    "                            download_file_from_google_colab(file_name)\n",
    "                    print(f\"Downloaded: {file_name}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {document_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the request was successful\n",
    "if response.status_code == 200:    \n",
    "\n",
    "    projects_img = soup.findAll(\"tr\", {'class':['test-project-img', 'test-site-img']})\n",
    "    \n",
    "    for p in range(0, len(projects_img)):\n",
    "        img_project_date = datetime.strptime(projects_img[p].find_all(\"td\")[0].get_text(strip=True), '%d %b %Y').strftime('%Y-%m-%d')\n",
    "        img_carrier = projects_img[p].find_all(\"td\")[1].get_text(strip=True)\n",
    "        if img_carrier:\n",
    "            img_carrier = '_' + img_carrier\n",
    "        \n",
    "        img_project_name = projects_img[p].find_all(\"td\")[2].get_text(strip=True).replace(img_carrier,'')\n",
    "        if img_project_name:\n",
    "            img_project_name = '_' + img_project_name\n",
    "            \n",
    "        img_System = projects_img[p].find_all(\"td\")[3].get_text(strip=True)\n",
    "        \n",
    "        id_img = projects_img[p].find_all(\"td\")[4].find('a')['data-target'].replace('#','')\n",
    "        images = soup.find(\"div\", {\"id\": id_img}).select('tr.test-site-inner-doc.clickable-row')\n",
    "        images_dates_time_list = []\n",
    "        images = soup.find(\"div\", {\"id\": id_img}).select('table')[0]\n",
    "        for j in images.find_all('tr')[1:]:\n",
    "                    images_dates_time_list.extend([tv.text.strip() for tv in j.select('td:nth-of-type(4)')] )\n",
    "        images_dates_list = []\n",
    "        for x in list(dict.fromkeys(images_dates_time_list)):\n",
    "            images_dates_list.append(datetime.strptime(x, '%d %b %Y %H:%M:%S').strftime('%Y-%m-%d'))\n",
    "        latest_image_date = max(images_dates_list)\n",
    "        \n",
    "        img_url = 'https://www.rfnsa.com.au'+ soup.find(\"div\", {\"id\": id_img}).find_all(\"a\", class_=\"download-document\")[0]['data-url']+'&sid=' + sid\n",
    "\n",
    "        img_file_name =  f\"{RFNSA_No}_{latest_image_date}{img_carrier}{img_project_name}.zip\"\n",
    "        img_response = session.get(img_url, headers={'User-Agent':'Mozilla/5.0 (Linux; Android 12; SM-S906N Build/QP1A.190711.020; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/80.0.3987.119 Mobile Safari/537.36',\n",
    "                            'Cookie': session_cookie})  \n",
    "        if img_response.status_code == 200:\n",
    "                    # Save the document with the new name\n",
    "                with open(img_file_name, \"wb\") as file:\n",
    "                    file.write(img_response.content)\n",
    "                    if 'google.colab' in str(get_ipython()):\n",
    "                        download_file_from_google_colab(img_file_name)\n",
    "                print(f\"Downloaded: {img_file_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {img_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42223c82",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check if the document is a zip file\n",
    "                if document_response.headers.get(\"Content-Type\") == \"application/zip\":\n",
    "                    zip_file_path = \"temp.zip\"\n",
    "                    with open(zip_file_path, \"wb\") as zip_file:\n",
    "                        zip_file.write(document_response.content)\n",
    "\n",
    "                    # Unzip the file\n",
    "                    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "                        # Extract and save the files with the new names\n",
    "                        for zip_info in zip_ref.infolist():\n",
    "                            extracted_file_name = f\"{carrier}_{project_name}_{upload_date.replace(' ', '_')}_{zip_info.filename}\"\n",
    "                            zip_ref.extract(zip_info, path=extracted_file_name)\n",
    "                            if 'google.colab' in str(get_ipython()):\n",
    "                                download_file_from_google_colab(extracted_file_name)\n",
    "\n",
    "                    # Remove the original zip file\n",
    "                    os.remove(zip_file_path)\n",
    "\n",
    "                    print(f\"Unzipped and copied to roof folder: {file_name}\")\n",
    "                else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e9f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
